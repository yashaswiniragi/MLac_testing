#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
This file is automatically generated by AION for AI0017_1 usecase.
File generation time: 2023-02-21 10:13:56
'''
import os
os.path.abspath(os.path.join(__file__, os.pardir))

#Standard Library modules
import warnings
import json
import logging
import sys
import argparse

#Third Party modules
from pathlib import Path
import pandas as pd 
import joblib
from sklearn.preprocessing import MinMaxScaler

#local modules
from utility import *

warnings.filterwarnings("ignore")

IOFiles = {
    "inputData": "rawData.dat",
    "metaData": "modelMetaData.json",
    "log": "aion.log",
    "transformedData": "transformedData.dat",
    "normalization": "normalization.pkl"
}
        
def validateConfig():        
    config_file = Path(__file__).parent/'config.json'        
    if not Path(config_file).exists():        
        raise ValueError(f'Config file is missing: {config_file}')        
    config = read_json(config_file)        
    return config

def transformation(config, targetPath, log):
    dataLoc = targetPath / IOFiles['inputData']
    if not dataLoc.exists():
        return {'Status': 'Failure', 'Message': 'Data location does not exists.'}
    df = read_data(dataLoc)
    log.log_dataframe(df)

    target_feature = config['target_feature']
    dateTimeFeature=config['dateTimeFeature']
    df.set_index(dateTimeFeature, inplace=True)
    df = df.dropna()
    df=df.fillna(df.mean())
    if len(target_feature) == 1:
        trainX = df[target_feature].to_numpy().reshape(-1,1)
    else:
        trainX = df[target_feature].to_numpy()
    
    scaler = MinMaxScaler(feature_range=(0, 1))
    trainX = scaler.fit_transform(trainX)
    normalization_file_name = str(targetPath / IOFiles['normalization'])
    joblib.dump(scaler, normalization_file_name)
    
    df[target_feature] = trainX
    log.log_dataframe(df)
    csv_path = str(targetPath / IOFiles['transformedData'])
    write_data(df, csv_path, index=True)

    status = {'Status': 'Success', 'DataFilePath': IOFiles['transformedData'],
            'target_feature': target_feature,'dateTimeFeature':dateTimeFeature,
              "Normalization_file":normalization_file_name }
    meta_data['transformation'] = {}
    meta_data['transformation']['Status'] = status
    write_json(meta_data, str(targetPath / IOFiles['metaData']))
    log.info(f'Transformed data saved at {csv_path}')
    log.info(f'output: {status}')
    return json.dumps(status)
        
if __name__ == '__main__':
    config = validateConfig()
    targetPath = Path('aion') / config['targetPath']
    if not targetPath.exists():
        raise ValueError(f'targetPath does not exist')
    meta_data_file = targetPath / IOFiles['metaData']
    if meta_data_file.exists():
        meta_data = read_json(meta_data_file)
    else:
        raise ValueError(f'Configuration file not found: {meta_data_file}')
    log_file = targetPath / IOFiles['log']
    log = logger(log_file, mode='a', logger_name=Path(__file__).parent.stem)
    try:
        print(transformation(config, targetPath, log))
    except Exception as e:
        
        status = {'Status': 'Failure', 'Message': str(e)}
        print(json.dumps(status))
    