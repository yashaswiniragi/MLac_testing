#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
This file is automatically generated by AION for AI0017_1 usecase.
File generation time: 2023-02-21 10:13:56
'''
#Standard Library modules
import json
import argparse
import platform

#Third Party modules
from pathlib import Path
import pandas as pd 

#local modules
from utility import *
from data_reader import dataReader

IOFiles = {
    "rawData": "rawData.dat",
    "metaData": "modelMetaData.json",
    "log": "aion.log",
    "outputData": "rawData.dat",
    "monitoring": "monitoring.json",
    "prodData": "prodData",
    "prodDataGT": "prodDataGT"
}
        
def validateConfig():        
    config_file = Path(__file__).parent/'config.json'        
    if not Path(config_file).exists():        
        raise ValueError(f'Config file is missing: {config_file}')        
    config = read_json(config_file)		
    if not config['targetPath']:        
        raise ValueError(f'Target Path is not configured')        
    return config

#This function will read the data and save the data on persistent storage        
def load_data(config, targetPath, log):        
    meta_data_file = targetPath / IOFiles['metaData']
    meta_data = read_json(meta_data_file)
    if meta_data.get('monitoring', False) and not meta_data['monitoring'].get('retrain', False):
        raise ValueError('New data is not enougth to retrain model')
    df = read_data(config['dataLocation'])
    status = {}
    output_data_path = targetPath / IOFiles['outputData']
    log.log_dataframe(df)
    required_features = list(set(config['selected_features'] + config['dateTimeFeature'] + config['target_feature']))
    log.info('Dataset features required: ' + ','.join(required_features))
    missing_features = [x for x in required_features if x not in df.columns.tolist()]
    if missing_features:
        raise ValueError(f'Some feature/s is/are missing: {missing_features}')
    log.info('Removing unused features: ' + ','.join(list(set(df.columns) - set(required_features))))
    df = df[required_features]
    log.info(f'Required features: {required_features}')
    try:
        log.info(f'Saving Dataset: {str(output_data_path)}')
        write_data(df, output_data_path, index=False)
        status = {'Status': 'Success', 'DataFilePath': IOFiles['outputData'], 'Records': len(df)}
    except:
        raise ValueError('Unable to create data file')

    meta_data['load_data'] = {}
    meta_data['load_data']['selected_features'] = [x for x in config['selected_features'] if
            x != config['target_feature']]
    meta_data['load_data']['Status'] = status
    write_json(meta_data, meta_data_file)
    output = json.dumps(status)
    log.info(output)
    return output

if __name__ == '__main__':
    config = validateConfig()
    targetPath = Path('aion') / config['targetPath']
    targetPath.mkdir(parents=True, exist_ok=True)	
    if not targetPath.exists():
        raise ValueError(f'targetPath does not exist')
    meta_data_file = targetPath / IOFiles['metaData']
    if not meta_data_file.exists():
        raise ValueError(f'Configuration file not found: {meta_data_file}')
    log_file = targetPath / IOFiles['log']
    log = logger(log_file, mode='a', logger_name=Path(__file__).parent.stem)
    try:
        print(load_data(config, targetPath, log))
    except Exception as e:
        status = {'Status': 'Failure', 'Message': str(e)}
        print(json.dumps(status))
    