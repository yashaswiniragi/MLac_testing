#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
This file is automatically generated by AION for AI0014_1 usecase.
File generation time: 2023-02-20 16:38:28
'''
#Standard Library modules
import platform
import time
import sys
import json
import logging
import argparse

#Third Party modules
from pathlib import Path
import pandas as pd 
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import Lasso

#local modules
from utility import *

IOFiles = {
    "inputData": "transformedData.dat",
    "metaData": "modelMetaData.json",
    "log": "aion.log",
    "outputData": "featureEngineeredData.dat"
}
        
def validateConfig():        
    config_file = Path(__file__).parent/'config.json'        
    if not Path(config_file).exists():        
        raise ValueError(f'Config file is missing: {config_file}')        
    config = read_json(config_file)        
    return config


def featureSelector(log):        
    config = validateConfig()        
    targetPath = Path('aion')/config['targetPath']        
    if not targetPath.exists():        
        raise ValueError(f'targetPath does not exist')        
    meta_data_file = targetPath/IOFiles['metaData']        
    if meta_data_file.exists():        
        meta_data = read_json(meta_data_file)        
    else:        
        raise ValueError(f'Configuration file not found: {meta_data_file}')        
    log_file = targetPath/IOFiles['log']        
    log = logger(log_file, mode='a', logger_name=Path(__file__).parent.stem)        
    dataLoc = targetPath/IOFiles['inputData']        
    if not dataLoc.exists():        
        return {'Status':'Failure','Message':'Data location does not exists.'}        
        
    status = dict()        
    df = pd.read_csv(dataLoc)        
    prev_step_output = meta_data['transformation']
    train_features = df.columns.tolist()
    target_feature = config['target_feature']
    train_features.remove(target_feature)
    cat_features = prev_step_output['cat_features']
    total_features = []
    log.log_dataframe(df)
    selected_features = {}
    meta_data['featureengineering']= {}
    log.info('Model Based Correlation Analysis Start')
    selector = SelectFromModel(Lasso())
    selector.fit(df[train_features],df[target_feature])
    model_based_feat = df[train_features].columns[(selector.get_support())].tolist()
    if target_feature in model_based_feat:
        model_based_feat.remove(target_feature)
    selected_features['modelBased'] = model_based_feat
    log.info('Highly Correlated Features : {model_based_feat}')
    total_features = list(set([x for y in selected_features.values() for x in y] + [target_feature]))
    df = df[total_features]
    log.log_dataframe(df)
                
    csv_path = str(targetPath/IOFiles['outputData'])                
    write_data(df, csv_path,index=False)                
    status = {'Status':'Success','DataFilePath':IOFiles['outputData'],'total_features':total_features, 'selected_features':selected_features}                
    log.info(f'Selected data saved at {csv_path}')                
    meta_data['featureengineering']['Status'] = status                
    write_json(meta_data, str(targetPath/IOFiles['metaData']))                
    log.info(f'output: {status}')                
    return json.dumps(status)
        
if __name__ == '__main__':        
    log = None        
    try:        
        print(featureSelector(log))        
    except Exception as e:        
        if log:        
            log.error(e, exc_info=True)        
        status = {'Status':'Failure','Message':str(e)}        
        print(json.dumps(status))        