#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
This file is automatically generated by AION for AI0014_1 usecase.
File generation time: 2023-02-20 16:38:27
'''
import os
os.path.abspath(os.path.join(__file__, os.pardir))

#Standard Library modules
import warnings
import json
import sys
import logging
import argparse

#Third Party modules
from pathlib import Path
import pandas as pd 
import scipy
from sklearn.model_selection import train_test_split
import joblib

#local modules
from utility import *
from dataProfiler import profiler

warnings.filterwarnings("ignore")

IOFiles = {
    "inputData": "rawData.dat",
    "metaData": "modelMetaData.json",
    "log": "aion.log",
    "trainData": "transformedData.dat",
    "testData": "test.dat",
    "preprocessor": "preprocessor.pkl"
}
        
def validateConfig():        
    config_file = Path(__file__).parent/'config.json'        
    if not Path(config_file).exists():        
        raise ValueError(f'Config file is missing: {config_file}')        
    config = read_json(config_file)        
    return config

def transformation(log):
    config = validateConfig()        
    targetPath = Path('aion')/config['targetPath']        
    if not targetPath.exists():        
        raise ValueError(f'targetPath does not exist')        
    meta_data_file = targetPath/IOFiles['metaData']        
    if meta_data_file.exists():        
        meta_data = read_json(meta_data_file)        
    else:        
        raise ValueError(f'Configuration file not found: {meta_data_file}')        
    log_file = targetPath/IOFiles['log']        
    log = logger(log_file, mode='a', logger_name=Path(__file__).parent.stem)        
    dataLoc = targetPath/IOFiles['inputData']        
    if not dataLoc.exists():        
        return {'Status':'Failure','Message':'Data location does not exists.'}        
    status = dict()        
    df = read_data(dataLoc)        
    log.log_dataframe(df)        
    target_feature = config['target_feature']
        
    train_data, test_data = train_test_split(df,train_size=config['train_ratio'])
    profilerObj = profiler(xtrain=train_data, target=target_feature,  config=config['profiler'],log=log)
    train_data, preprocess_pipe, label_encoder = profilerObj.transform()
    if not preprocess_pipe:
        raise ValueError('Pipeline not created')
    joblib.dump(preprocess_pipe, targetPath/IOFiles['preprocessor'])
    test_data.reset_index(inplace=True)    

        
    ytest = test_data[target_feature]
        
    test_data.astype(profilerObj.train_features_type)
    test_data = preprocess_pipe.transform(test_data)
    if isinstance(test_data, scipy.sparse.spmatrix):
        test_data = test_data.toarray()
    preprocess_out_columns = train_data.columns.tolist()
    preprocess_out_columns.remove(target_feature)
    test_data = pd.DataFrame(test_data, columns=preprocess_out_columns)
    test_data[target_feature] = ytest
    write_data(train_data,targetPath/IOFiles['trainData'],index=False)
    write_data(test_data,targetPath/IOFiles['testData'],index=False)
        
    log.log_dataframe(train_data)                
    status = {'Status':'Success','trainData':IOFiles['trainData'],'testData':IOFiles['testData']}                
    meta_data['transformation'] = {}
    meta_data['transformation']['cat_features'] = train_data.select_dtypes('category').columns.tolist()
    meta_data['transformation']['preprocessor'] = IOFiles['preprocessor']
    meta_data['transformation']['preprocess_out_columns'] = preprocess_out_columns
        
    meta_data['transformation']['Status'] = status                
    write_json(meta_data, str(targetPath/IOFiles['metaData']))                
    log.info(f"Transformed data saved at {targetPath/IOFiles['trainData']}")                
    log.info(f'output: {status}')                
    return json.dumps(status)
        
        
if __name__ == '__main__':        
    log = None        
    try:        
        print(transformation(log))        
    except Exception as e:        
        if log:        
            log.error(e, exc_info=True)        
        status = {'Status':'Failure','Message':str(e)}        
        print(json.dumps(status))